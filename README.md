# ğŸš€ ML Toolkit MLOps - Architecture ComplÃ¨te

SystÃ¨me automatisÃ© de dÃ©tection de malwares avec pipeline MLOps complet.

## ğŸ“‹ Table des MatiÃ¨res

- [Architecture](#architecture)
- [Services](#services)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Monitoring](#monitoring)
- [API](#api)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MLOPS ARCHITECTURE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ğŸ“Š Data Collection                                         â”‚
â”‚  â””â”€> Malware samples + Benign files                         â”‚
â”‚       â””â”€> DVC (Data Version Control)                        â”‚
â”‚                                                             â”‚
â”‚  ğŸ”„ Airflow Pipeline (Daily)                                â”‚
â”‚  â”œâ”€> Check Data Availability                                â”‚
â”‚  â”œâ”€> Extract Features (binary_features.py)                  â”‚
â”‚  â”œâ”€> Train Model (auto_trainer.py)                          â”‚
â”‚  â”œâ”€> Evaluate Performance                                   â”‚
â”‚  â””â”€> Deploy Model                                           â”‚
â”‚                                                             â”‚
â”‚  ğŸ¤– BentoML API                                             â”‚
â”‚  â””â”€> REST API for malware detection                         â”‚
â”‚       POST /scan_file â†’ {is_malware, confidence}            â”‚
â”‚                                                             â”‚
â”‚  ğŸ“ˆ Monitoring                                              â”‚
â”‚  â”œâ”€> Prometheus (Metrics)                                   â”‚
â”‚  â””â”€> Grafana (Dashboards)                                   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Services

### 1. **ML Toolkit** (Port: interne)
Application principale de Machine Learning
- Extraction de features binaires
- EntraÃ®nement automatique de modÃ¨les
- Support multi-types de donnÃ©es

### 2. **Airflow** (Port: 8080)
Orchestration du pipeline ML
- **Webserver**: Interface de gestion
- **Scheduler**: Planification des tÃ¢ches
- **Worker**: ExÃ©cution des jobs
- **Login**: `admin` / `admin`

### 3. **BentoML** (Port: 3000)
API REST pour dÃ©tection en temps rÃ©el
- Endpoint: `POST /scan_file`
- Analyse de fichiers suspects
- RÃ©ponse avec confiance et features

### 4. **PostgreSQL** (Port: 5432)
Base de donnÃ©es pour Airflow
- Stockage mÃ©tadonnÃ©es des DAGs
- Historique des exÃ©cutions

### 5. **Redis** (Port: 6379)
Message broker pour Celery (Airflow)
- File d'attente des tÃ¢ches
- Communication inter-workers

### 6. **Prometheus** (Port: 9090)
Collecte de mÃ©triques
- Performance des modÃ¨les
- SantÃ© des services
- Utilisation ressources

### 7. **Grafana** (Port: 3001)
Visualisation et dashboards
- **Login**: `admin` / `admin`
- MÃ©triques temps rÃ©el
- Alertes personnalisÃ©es

---

## âš™ï¸ Installation

### PrÃ©requis

- Docker & Docker Compose
- Git
- 8GB RAM minimum
- 20GB espace disque

### ğŸš€ DÃ©marrage Rapide

```bash
# 1. Cloner le repository
git clone git@github.com:TatianaT13/ml_toolkit.git
cd ml_toolkit

# 2. Copier les fichiers MLOps
# (Les fichiers Dockerfile, docker-compose.yml, etc.)

# 3. CrÃ©er la structure de donnÃ©es
mkdir -p data/{malware_samples,benign_samples} models

# 4. Lancer tous les services
docker-compose up -d

# 5. VÃ©rifier que tout est dÃ©marrÃ©
docker-compose ps
```

### ğŸ“Š Initialisation d'Airflow

```bash
# Attendre que tous les services soient UP (~2 minutes)
docker-compose logs -f airflow-webserver

# Quand vous voyez "Airflow Webserver started"
# Ouvrir http://localhost:8080
# Login: admin / admin
```

---

## ğŸ¯ Utilisation

### 1ï¸âƒ£ Pipeline Automatique (Airflow)

Le pipeline s'exÃ©cute **automatiquement chaque jour** :

1. **VÃ©rification des donnÃ©es** : Compte les fichiers disponibles
2. **GÃ©nÃ©ration synthÃ©tique** : Si pas assez de donnÃ©es
3. **Extraction features** : Analyse tous les fichiers
4. **EntraÃ®nement** : Teste 5 modÃ¨les ML
5. **Ã‰valuation** : GÃ©nÃ¨re un rapport
6. **DÃ©ploiement** : Met Ã  jour l'API

**Lancer manuellement** :
```bash
# Via l'interface Airflow
# http://localhost:8080 â†’ DAGs â†’ ml_malware_detection_pipeline â†’ Trigger

# Ou via CLI
docker exec airflow-webserver airflow dags trigger ml_malware_detection_pipeline
```

### 2ï¸âƒ£ API de DÃ©tection (BentoML)

**Scanner un fichier suspect** :

```bash
# Test avec curl
curl -X POST http://localhost:3000/scan_file \
  -F "file=@suspicious_file.exe"

# RÃ©ponse
{
  "is_malware": true,
  "confidence": 0.95,
  "prediction": "MALWARE",
  "features": {
    "entropy": 7.82,
    "file_size": 1024,
    "printable_ratio": 0.15
  },
  "model_info": {
    "name": "RandomForest",
    "trained_at": "2024-02-10T19:00:00"
  }
}
```

**Python Client** :

```python
import requests

with open('file_to_scan.exe', 'rb') as f:
    response = requests.post(
        'http://localhost:3000/scan_file',
        files={'file': f}
    )

result = response.json()
if result['is_malware']:
    print(f"âš ï¸  MALWARE dÃ©tectÃ© ! Confiance: {result['confidence']:.2%}")
else:
    print(f"âœ… Fichier lÃ©gitime. Confiance: {result['confidence']:.2%}")
```

### 3ï¸âƒ£ Ajouter Vos DonnÃ©es

```bash
# Copier vos fichiers malwares
cp /path/to/malwares/* data/malware_samples/

# Copier vos fichiers lÃ©gitimes
cp /path/to/benign/* data/benign_samples/

# Le prochain run du pipeline les utilisera automatiquement
```

### 4ï¸âƒ£ Versioning avec DVC

```bash
# Installer DVC
pip install dvc

# Initialiser DVC dans le projet
dvc init

# Tracker les donnÃ©es
dvc add data/malware_samples
dvc add data/benign_samples
dvc add models/

# Pousser vers DagsHub
dvc push

# Git commit
git add .
git commit -m "Update datasets and models"
git push
```

---

## ğŸ“Š Monitoring

### Prometheus (http://localhost:9090)

**MÃ©triques disponibles** :
- Taux de prÃ©dictions malware vs benign
- Temps de rÃ©ponse API
- Accuracy du modÃ¨le actuel
- Utilisation CPU/RAM

**Exemples de queries** :
```promql
# Nombre total de prÃ©dictions
sum(prediction_counter)

# Taux de malwares dÃ©tectÃ©s
rate(malware_detected[5m])

# Temps moyen de prÃ©diction
avg(prediction_duration_seconds)
```

### Grafana (http://localhost:3001)

**Login** : `admin` / `admin`

**Dashboards Ã  crÃ©er** :
1. **ML Performance**
   - Accuracy over time
   - Confusion matrix
   - False positives/negatives

2. **API Monitoring**
   - Request rate
   - Response time
   - Error rate

3. **System Health**
   - CPU usage
   - Memory usage
   - Disk space

---

## ğŸ”§ Commandes Utiles

```bash
# Voir les logs d'un service
docker-compose logs -f airflow-webserver
docker-compose logs -f bentoml

# RedÃ©marrer un service
docker-compose restart airflow-scheduler

# AccÃ©der au shell d'un container
docker exec -it ml_toolkit_app bash

# Voir l'Ã©tat des services
docker-compose ps

# ArrÃªter tous les services
docker-compose down

# ArrÃªter et supprimer les volumes (âš ï¸ perte de donnÃ©es)
docker-compose down -v
```

---

## ğŸ“ Structure du Projet

```
ml_toolkit_mlops/
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ Dockerfile.airflow           # Image Airflow personnalisÃ©e
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ ml_pipeline_dag.py       # Pipeline ML automatisÃ©
â”‚   â”œâ”€â”€ logs/                        # Logs Airflow
â”‚   â””â”€â”€ plugins/                     # Plugins personnalisÃ©s
â”œâ”€â”€ bentoml/
â”‚   â”œâ”€â”€ service.py                   # Service API
â”‚   â””â”€â”€ Dockerfile.bentoml           # Image BentoML
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml               # Config Prometheus
â”‚   â””â”€â”€ grafana-datasources.yml      # Datasources Grafana
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ malware_samples/             # Fichiers malveillants
â”‚   â””â”€â”€ benign_samples/              # Fichiers lÃ©gitimes
â”œâ”€â”€ models/                          # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ my_ml_toolkit/                   # Code source du toolkit
â”œâ”€â”€ Dockerfile                       # Image principale
â”œâ”€â”€ docker-compose.yml               # Orchestration
â””â”€â”€ README.md                        # Ce fichier
```

---

## ğŸ“ Cas d'Usage

### 1. **DÃ©tection de Malwares en Production**
- Upload de fichiers suspects via API
- Analyse automatique en temps rÃ©el
- Alertes si malware dÃ©tectÃ©

### 2. **Recherche en CybersÃ©curitÃ©**
- Dataset versionnÃ© avec DVC
- ExpÃ©rimentation de nouvelles features
- Comparaison de modÃ¨les

### 3. **Formation et Apprentissage**
- Pipeline ML complet de bout en bout
- Best practices MLOps
- Monitoring et observabilitÃ©

---

## ğŸ› Troubleshooting

### Airflow ne dÃ©marre pas
```bash
# RÃ©initialiser la DB
docker-compose down -v
docker-compose up -d
```

### BentoML erreur "Model not found"
```bash
# VÃ©rifier que le modÃ¨le existe
ls -la models/malware_detector.pkl

# Lancer le pipeline Airflow pour gÃ©nÃ©rer un modÃ¨le
```

### Prometheus ne collecte pas de mÃ©triques
```bash
# VÃ©rifier la config
docker exec prometheus cat /etc/prometheus/prometheus.yml

# RedÃ©marrer Prometheus
docker-compose restart prometheus
```

---

## ğŸš€ Prochaines AmÃ©liorations

- [ ] IntÃ©gration CI/CD (GitHub Actions)
- [ ] Tests automatisÃ©s du pipeline
- [ ] Dashboard Grafana prÃ©configurÃ©
- [ ] Alertes Slack/Email
- [ ] Support pour datasets externes (VirusTotal)
- [ ] A/B testing de modÃ¨les
- [ ] Export de mÃ©triques custom

---

## ğŸ“„ License

MIT License - Utilisation libre

---

## ğŸ‘¤ Auteur

**Tetyana Tarasenko**  
GitHub: [@TatianaT13](https://github.com/TatianaT13)

---

## ğŸ™ Contribution

Les contributions sont les bienvenues !

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/amazing`)
3. Commit (`git commit -m 'Add amazing feature'`)
4. Push (`git push origin feature/amazing`)
5. Ouvrir une Pull Request

---

**ğŸ‰ Bon apprentissage MLOps !**
